{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCOescy2SrvDmhCoW9Obri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hl5chen/ECE1512-2022F-ProjectRepo_YiyangShi_HsuanlingChen/blob/main/Project_B_Supp/Task1/ECE1512_2e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXK_Z_18YxZr",
        "outputId": "73201f0a-93e9-4c24-a624-ed8d914ac45c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import_ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (5.7.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.6.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (5.1.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.11.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import_ipynb) (2.5.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4I0TX1OXqFE",
        "outputId": "c10be4c0-d48c-4920-a6e9-2ce5b9fec381"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Colab Notebooks/ECE1512_F22/ProjectB/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qObQMY9YX95A",
        "outputId": "ea5c274f-06f9-476a-ec29-3184171ebf92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/ECE1512_F22/ProjectB/'\n",
            "/content/drive/MyDrive/Colab Notebooks/ECE1512_F22/ProjectB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load up distilled dataset and train model"
      ],
      "metadata": {
        "id": "zV6_xyDaWxrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import time\n",
        "\n",
        "class myArgs:\n",
        "  def __init__(self):\n",
        "    self.method = 'DC'\n",
        "    self.dataset = 'CIFAR10'\n",
        "    self.model = 'ConvNet'\n",
        "    self.ipc = 10\n",
        "    self.eval_mode = 'S'\n",
        "    self.num_exp = 1\n",
        "    self.num_eval = 5\n",
        "    self.epoch_eval_train = 300\n",
        "    self.Iteration = 100\n",
        "    self.lr_img = 0.1\n",
        "    self.lr_net = 0.01\n",
        "    self.batch_real = 256\n",
        "    self.batch_train = 256\n",
        "    self.init = 'real'\n",
        "    self.dsa_strategy = 'None'\n",
        "    self.data_path = 'data'\n",
        "    self.save_path = 'result'\n",
        "    self.dis_metric = 'ours'\n",
        "\n",
        "args = myArgs()\n",
        "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.dsa_param = ParamDiffAug()\n",
        "args.dsa = True if args.method == 'DSA' else False\n",
        "\n",
        "\n",
        "distilled_set_name = 'result/res_DC_CIFAR10_ConvNet_10ipc.pt'\n",
        "dataset = torch.load(distilled_set_name)\n",
        "syn_data = dataset['data']\n",
        "syn_data = TensorDataset(syn_data[0][0], syn_data[0][1])\n",
        "\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
        "net = get_network(args.model, channel, num_classes, im_size).to(args.device)\n",
        "\n",
        "\n",
        "net.train()\n",
        "optimizer_net = torch.optim.SGD(net.parameters(), lr=0.01)  # optimizer_img for synthetic data\n",
        "optimizer_net.zero_grad()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(syn_data, batch_size=1, shuffle=True, num_workers=0)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, num_epochs)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  loss_avg, acc_avg = epoch('train', trainloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "  for param_group in optimizer_net.param_groups:\n",
        "    print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "\n",
        "  print(\"Epoch[{}/{}]: Loss: {:.4f}, ACC: {:.4f}\".format(i+1,num_epochs, loss_avg, acc_avg))\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "print('Training on synthetic CIFAR10 dataset took {} seconds'.format(time.time()-start))\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(dst_test, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
        "net.eval()\n",
        "loss_avg, acc_avg = epoch('test', testloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "\n",
        "print(\"Test set: Loss: {:.4f}, ACC: {:.4f}\".format(loss_avg, acc_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQvEtZk-W0wR",
        "outputId": "3c388b4d-e153-45c7-8757-be8066f60177"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current learning rate is: 0.01\n",
            "Epoch[1/20]: Loss: 4.7377, ACC: 0.0800\n",
            "Current learning rate is: 0.009938441702975689\n",
            "Epoch[2/20]: Loss: 3.1479, ACC: 0.1500\n",
            "Current learning rate is: 0.009755282581475769\n",
            "Epoch[3/20]: Loss: 2.2229, ACC: 0.3000\n",
            "Current learning rate is: 0.00945503262094184\n",
            "Epoch[4/20]: Loss: 1.4145, ACC: 0.5000\n",
            "Current learning rate is: 0.009045084971874739\n",
            "Epoch[5/20]: Loss: 0.6055, ACC: 0.7400\n",
            "Current learning rate is: 0.008535533905932738\n",
            "Epoch[6/20]: Loss: 0.2835, ACC: 0.9500\n",
            "Current learning rate is: 0.007938926261462366\n",
            "Epoch[7/20]: Loss: 0.0843, ACC: 1.0000\n",
            "Current learning rate is: 0.007269952498697735\n",
            "Epoch[8/20]: Loss: 0.0447, ACC: 1.0000\n",
            "Current learning rate is: 0.006545084971874738\n",
            "Epoch[9/20]: Loss: 0.0332, ACC: 1.0000\n",
            "Current learning rate is: 0.005782172325201155\n",
            "Epoch[10/20]: Loss: 0.0277, ACC: 1.0000\n",
            "Current learning rate is: 0.005\n",
            "Epoch[11/20]: Loss: 0.0246, ACC: 1.0000\n",
            "Current learning rate is: 0.004217827674798847\n",
            "Epoch[12/20]: Loss: 0.0222, ACC: 1.0000\n",
            "Current learning rate is: 0.0034549150281252636\n",
            "Epoch[13/20]: Loss: 0.0207, ACC: 1.0000\n",
            "Current learning rate is: 0.0027300475013022664\n",
            "Epoch[14/20]: Loss: 0.0196, ACC: 1.0000\n",
            "Current learning rate is: 0.0020610737385376348\n",
            "Epoch[15/20]: Loss: 0.0188, ACC: 1.0000\n",
            "Current learning rate is: 0.0014644660940672626\n",
            "Epoch[16/20]: Loss: 0.0182, ACC: 1.0000\n",
            "Current learning rate is: 0.0009549150281252633\n",
            "Epoch[17/20]: Loss: 0.0178, ACC: 1.0000\n",
            "Current learning rate is: 0.0005449673790581611\n",
            "Epoch[18/20]: Loss: 0.0175, ACC: 1.0000\n",
            "Current learning rate is: 0.00024471741852423234\n",
            "Epoch[19/20]: Loss: 0.0173, ACC: 1.0000\n",
            "Current learning rate is: 6.15582970243117e-05\n",
            "Epoch[20/20]: Loss: 0.0172, ACC: 1.0000\n",
            "24.36486792564392\n",
            "Test set: Loss: 2.2044, ACC: 0.3726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import time\n",
        "\n",
        "class myArgs:\n",
        "  def __init__(self):\n",
        "    self.method = 'DC'\n",
        "    self.dataset = 'CIFAR10'\n",
        "    self.model = 'ConvNet'\n",
        "    self.ipc = 10\n",
        "    self.eval_mode = 'S'\n",
        "    self.num_exp = 1\n",
        "    self.num_eval = 5\n",
        "    self.epoch_eval_train = 300\n",
        "    self.Iteration = 100\n",
        "    self.lr_img = 0.1\n",
        "    self.lr_net = 0.01\n",
        "    self.batch_real = 256\n",
        "    self.batch_train = 256\n",
        "    self.init = 'real'\n",
        "    self.dsa_strategy = 'None'\n",
        "    self.data_path = 'data'\n",
        "    self.save_path = 'result'\n",
        "    self.dis_metric = 'ours'\n",
        "\n",
        "args = myArgs()\n",
        "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.dsa_param = ParamDiffAug()\n",
        "args.dsa = True if args.method == 'DSA' else False\n",
        "\n",
        "\n",
        "distilled_set_name = 'result_GM_CIFAR10_real/res_DC_CIFAR10_ConvNet_10ipc.pt'\n",
        "dataset = torch.load(distilled_set_name)\n",
        "syn_data = dataset['data']\n",
        "syn_data = TensorDataset(syn_data[0][0], syn_data[0][1])\n",
        "\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
        "net = get_network(args.model, channel, num_classes, im_size).to(args.device)\n",
        "\n",
        "\n",
        "net.train()\n",
        "optimizer_net = torch.optim.SGD(net.parameters(), lr=0.01)  # optimizer_img for synthetic data\n",
        "optimizer_net.zero_grad()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(syn_data, batch_size=1, shuffle=True, num_workers=0)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, num_epochs)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  loss_avg, acc_avg = epoch('train', trainloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "  for param_group in optimizer_net.param_groups:\n",
        "    print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "\n",
        "  print(\"Epoch[{}/{}]: Loss: {:.4f}, ACC: {:.4f}\".format(i+1,num_epochs, loss_avg, acc_avg))\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "print('Training on synthetic CIFAR10 dataset took {} seconds'.format(time.time()-start))\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(dst_test, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
        "net.eval()\n",
        "loss_avg, acc_avg = epoch('test', testloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "\n",
        "print(\"Test set: Loss: {:.4f}, ACC: {:.4f}\".format(loss_avg, acc_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_2kbIOia6h6",
        "outputId": "68e5d288-eaf4-4dd2-c2c1-0c0981ce1a47"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Current learning rate is: 0.01\n",
            "Epoch[1/20]: Loss: 4.5661, ACC: 0.1000\n",
            "Current learning rate is: 0.009938441702975689\n",
            "Epoch[2/20]: Loss: 3.6608, ACC: 0.1400\n",
            "Current learning rate is: 0.009755282581475769\n",
            "Epoch[3/20]: Loss: 2.6013, ACC: 0.2600\n",
            "Current learning rate is: 0.00945503262094184\n",
            "Epoch[4/20]: Loss: 2.1328, ACC: 0.3000\n",
            "Current learning rate is: 0.009045084971874739\n",
            "Epoch[5/20]: Loss: 1.3143, ACC: 0.5200\n",
            "Current learning rate is: 0.008535533905932738\n",
            "Epoch[6/20]: Loss: 0.7344, ACC: 0.7800\n",
            "Current learning rate is: 0.007938926261462366\n",
            "Epoch[7/20]: Loss: 0.4030, ACC: 0.8900\n",
            "Current learning rate is: 0.007269952498697735\n",
            "Epoch[8/20]: Loss: 0.1414, ACC: 0.9900\n",
            "Current learning rate is: 0.006545084971874738\n",
            "Epoch[9/20]: Loss: 0.0891, ACC: 1.0000\n",
            "Current learning rate is: 0.005782172325201155\n",
            "Epoch[10/20]: Loss: 0.0585, ACC: 1.0000\n",
            "Current learning rate is: 0.005\n",
            "Epoch[11/20]: Loss: 0.0475, ACC: 1.0000\n",
            "Current learning rate is: 0.004217827674798847\n",
            "Epoch[12/20]: Loss: 0.0417, ACC: 1.0000\n",
            "Current learning rate is: 0.0034549150281252636\n",
            "Epoch[13/20]: Loss: 0.0379, ACC: 1.0000\n",
            "Current learning rate is: 0.0027300475013022664\n",
            "Epoch[14/20]: Loss: 0.0350, ACC: 1.0000\n",
            "Current learning rate is: 0.0020610737385376348\n",
            "Epoch[15/20]: Loss: 0.0331, ACC: 1.0000\n",
            "Current learning rate is: 0.0014644660940672626\n",
            "Epoch[16/20]: Loss: 0.0317, ACC: 1.0000\n",
            "Current learning rate is: 0.0009549150281252633\n",
            "Epoch[17/20]: Loss: 0.0308, ACC: 1.0000\n",
            "Current learning rate is: 0.0005449673790581611\n",
            "Epoch[18/20]: Loss: 0.0302, ACC: 1.0000\n",
            "Current learning rate is: 0.00024471741852423234\n",
            "Epoch[19/20]: Loss: 0.0298, ACC: 1.0000\n",
            "Current learning rate is: 6.15582970243117e-05\n",
            "Epoch[20/20]: Loss: 0.0296, ACC: 1.0000\n",
            "Training on synthetic CIFAR10 dataset took 21.65150499343872 seconds\n",
            "Test set: Loss: 2.0670, ACC: 0.3850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import time\n",
        "\n",
        "class myArgs:\n",
        "  def __init__(self):\n",
        "    self.method = 'DC'\n",
        "    self.dataset = 'CIFAR10'\n",
        "    self.model = 'ConvNet'\n",
        "    self.ipc = 10\n",
        "    self.eval_mode = 'S'\n",
        "    self.num_exp = 1\n",
        "    self.num_eval = 5\n",
        "    self.epoch_eval_train = 300\n",
        "    self.Iteration = 100\n",
        "    self.lr_img = 0.1\n",
        "    self.lr_net = 0.01\n",
        "    self.batch_real = 256\n",
        "    self.batch_train = 256\n",
        "    self.init = 'real'\n",
        "    self.dsa_strategy = 'None'\n",
        "    self.data_path = 'data'\n",
        "    self.save_path = 'result'\n",
        "    self.dis_metric = 'ours'\n",
        "\n",
        "args = myArgs()\n",
        "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.dsa_param = ParamDiffAug()\n",
        "args.dsa = True if args.method == 'DSA' else False\n",
        "\n",
        "\n",
        "distilled_set_name = 'result_GM_CIFAR10_noise/res_DC_CIFAR10_ConvNet_10ipc.pt'\n",
        "dataset = torch.load(distilled_set_name)\n",
        "syn_data = dataset['data']\n",
        "syn_data = TensorDataset(syn_data[0][0], syn_data[0][1])\n",
        "\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
        "net = get_network(args.model, channel, num_classes, im_size).to(args.device)\n",
        "\n",
        "\n",
        "net.train()\n",
        "optimizer_net = torch.optim.SGD(net.parameters(), lr=0.01)  # optimizer_img for synthetic data\n",
        "optimizer_net.zero_grad()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(syn_data, batch_size=1, shuffle=True, num_workers=0)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, num_epochs)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  loss_avg, acc_avg = epoch('train', trainloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "  for param_group in optimizer_net.param_groups:\n",
        "    print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "\n",
        "  print(\"Epoch[{}/{}]: Loss: {:.4f}, ACC: {:.4f}\".format(i+1,num_epochs, loss_avg, acc_avg))\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "print('Training on synthetic CIFAR10 dataset took {} seconds'.format(time.time()-start))\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(dst_test, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
        "net.eval()\n",
        "loss_avg, acc_avg = epoch('test', testloader, net, optimizer_net, criterion, args, aug = True if args.dsa else False)\n",
        "\n",
        "print(\"Test set: Loss: {:.4f}, ACC: {:.4f}\".format(loss_avg, acc_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S74C5Gv4bZui",
        "outputId": "80393b17-00e9-477b-cfba-e4be558716f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Current learning rate is: 0.01\n",
            "Epoch[1/20]: Loss: 4.6467, ACC: 0.0800\n",
            "Current learning rate is: 0.009938441702975689\n",
            "Epoch[2/20]: Loss: 3.3095, ACC: 0.1600\n",
            "Current learning rate is: 0.009755282581475769\n",
            "Epoch[3/20]: Loss: 2.4250, ACC: 0.2500\n",
            "Current learning rate is: 0.00945503262094184\n",
            "Epoch[4/20]: Loss: 1.3810, ACC: 0.5500\n",
            "Current learning rate is: 0.009045084971874739\n",
            "Epoch[5/20]: Loss: 0.8884, ACC: 0.6600\n",
            "Current learning rate is: 0.008535533905932738\n",
            "Epoch[6/20]: Loss: 0.4493, ACC: 0.8600\n",
            "Current learning rate is: 0.007938926261462366\n",
            "Epoch[7/20]: Loss: 0.1973, ACC: 0.9900\n",
            "Current learning rate is: 0.007269952498697735\n",
            "Epoch[8/20]: Loss: 0.0890, ACC: 1.0000\n",
            "Current learning rate is: 0.006545084971874738\n",
            "Epoch[9/20]: Loss: 0.0490, ACC: 1.0000\n",
            "Current learning rate is: 0.005782172325201155\n",
            "Epoch[10/20]: Loss: 0.0395, ACC: 1.0000\n",
            "Current learning rate is: 0.005\n",
            "Epoch[11/20]: Loss: 0.0340, ACC: 1.0000\n",
            "Current learning rate is: 0.004217827674798847\n",
            "Epoch[12/20]: Loss: 0.0306, ACC: 1.0000\n",
            "Current learning rate is: 0.0034549150281252636\n",
            "Epoch[13/20]: Loss: 0.0282, ACC: 1.0000\n",
            "Current learning rate is: 0.0027300475013022664\n",
            "Epoch[14/20]: Loss: 0.0264, ACC: 1.0000\n",
            "Current learning rate is: 0.0020610737385376348\n",
            "Epoch[15/20]: Loss: 0.0251, ACC: 1.0000\n",
            "Current learning rate is: 0.0014644660940672626\n",
            "Epoch[16/20]: Loss: 0.0241, ACC: 1.0000\n",
            "Current learning rate is: 0.0009549150281252633\n",
            "Epoch[17/20]: Loss: 0.0235, ACC: 1.0000\n",
            "Current learning rate is: 0.0005449673790581611\n",
            "Epoch[18/20]: Loss: 0.0231, ACC: 1.0000\n",
            "Current learning rate is: 0.00024471741852423234\n",
            "Epoch[19/20]: Loss: 0.0228, ACC: 1.0000\n",
            "Current learning rate is: 6.15582970243117e-05\n",
            "Epoch[20/20]: Loss: 0.0227, ACC: 1.0000\n",
            "Training on synthetic CIFAR10 dataset took 21.603759765625 seconds\n",
            "Test set: Loss: 2.2863, ACC: 0.3537\n"
          ]
        }
      ]
    }
  ]
}