{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WYMfvCNPwpm"
      },
      "source": [
        "# Project A: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12 # 12\n",
        "NUM_CLASSES = 10  # 10 total classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EFLQROP2R7"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynByMG_UP4A4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f94825a28f884492ad69986c10ade538",
            "ad91a7d35be84776a47ddd331b83918f",
            "087cdf367a0b4fbbb16671b9478c88f7",
            "e57869527ac84b399a15d96695e7ccdd",
            "afbd6d79d9734a1bad0501b9048444cc",
            "c90094ab48584f048fccabfc0d10edfa",
            "a79c15b57ca04df4bead6008e4040f2d",
            "f972f555fa114f29bac3cae8303e4c18",
            "d3a99df67a754e7fbd74deca132b87ba",
            "79a15a8a1d104b438201ea0222e6e131",
            "655ed1b7561d46c9bdd72ee66500aa7f"
          ]
        },
        "outputId": "398e8e09-981b-44f7-8309-843000c8aba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f94825a28f884492ad69986c10ade538"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Load train and test splits.\n",
        "def preprocess(x):\n",
        "    image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
        "    subclass_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
        "    return image, subclass_labels\n",
        "\n",
        "\n",
        "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
        "mnist_train = mnist_train.map(preprocess)\n",
        "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
        "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "mnist_test = tfds.load('mnist', split='test').cache()\n",
        "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZwfvW5P63q"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zINgDkA7P7BP"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Build CNN teacher.\n",
        "import tensorflow.compat.v2.keras.layers as layers\n",
        "\n",
        "\n",
        "def initialize_cnn():\n",
        "  cnn_model = tf.keras.Sequential()\n",
        "\n",
        "  # your code start from here for stpe 2\n",
        "  cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  cnn_model.add(layers.MaxPooling2D((2, 2), strides=(1, 1)))\n",
        "  cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  cnn_model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "  cnn_model.add(layers.Flatten())\n",
        "  cnn_model.add(layers.Dropout(0.5))\n",
        "  cnn_model.add(layers.Dense(128, activation='relu'))\n",
        "  cnn_model.add(layers.Dropout(0.5))\n",
        "  cnn_model.add(layers.Dense(10))\n",
        "  return cnn_model\n",
        "\n",
        "\n",
        "\n",
        "def initialize_fc():\n",
        "  # Build fully connected student.\n",
        "  fc_model = tf.keras.Sequential()\n",
        "  fc_model.add(layers.Flatten())\n",
        "  fc_model.add(layers.Dense(784, activation='relu'))\n",
        "  fc_model.add(layers.Dense(784, activation='relu'))\n",
        "  fc_model.add(layers.Dense(10))\n",
        "  return fc_model\n",
        "\n",
        "cnn_model = initialize_cnn()\n",
        "fc_model = initialize_fc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWGucyrQGav"
      },
      "source": [
        "# Teacher loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "    \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "    Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    subclass_logits = cnn_model(images, training=True)\n",
        "\n",
        "    # your code start from here for step 3\n",
        "\n",
        "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits)\n",
        "\n",
        "    return tf.reduce_mean(cross_entropy_loss_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "    \"\"\"Compute distillation loss.\n",
        "\n",
        "    This function computes cross entropy between softened logits and softened\n",
        "    targets. The resulting loss is scaled by the squared temperature so that\n",
        "    the gradient magnitude remains approximately constant as the temperature is\n",
        "    changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "    a neural network.\"\n",
        "\n",
        "    Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "    Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "    \"\"\"\n",
        "    # your code start from here for step 3\n",
        "    soft_targets = tf.nn.softmax(teacher_logits / temperature)\n",
        "    '''\n",
        "    kl = tf.keras.losses.KLDivergence()\n",
        "\n",
        "\n",
        "    return tf.reduce_mean(kl(soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "    '''\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "    \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "    Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Scalar loss Tensor.\n",
        "    \"\"\"\n",
        "    student_subclass_logits = fc_model(images, training=True)\n",
        "\n",
        "    # Compute subclass distillation loss between student subclass logits and\n",
        "    # softened teacher subclass targets probabilities.\n",
        "\n",
        "    # your code start from here for step 3\n",
        "\n",
        "    teacher_subclass_logits = cnn_model(images, training=False)\n",
        "\n",
        "    student_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=student_subclass_logits)\n",
        "    student_loss_value = tf.reduce_mean(student_loss_value)\n",
        "\n",
        "    distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits, DISTILLATION_TEMPERATURE)\n",
        "    # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "    # your code start from here for step 3\n",
        "    student_loss = distillation_loss_value * ALPHA + student_loss_value * (1 - ALPHA)\n",
        "    #print(distillation_loss_value.numpy())\n",
        "\n",
        "    return student_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      },
      "source": [
        "# Train and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "    \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "    Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "    Returns:\n",
        "    Number of correctly classified images.\n",
        "    \"\"\"\n",
        "    class_logits = model(images, training=False)\n",
        "    return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32))\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn, compute_num_correct):\n",
        "    \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "    Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # your code start from here for step 4\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        # Run training.\n",
        "        print('Epoch {}: '.format(epoch), end='')\n",
        "        for images, labels in mnist_train:\n",
        "            with tf.GradientTape() as tape:\n",
        "                # your code start from here for step 4\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "                #print(\"loss value \" + str(loss_value.numpy()))\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Run evaluation.\n",
        "        num_correct = 0\n",
        "        num_total = builder.info.splits['test'].num_examples\n",
        "    \n",
        "        for images, labels in mnist_test:\n",
        "            # your code start from here for step 4\n",
        "            num_correct += compute_num_correct(model, images, labels)\n",
        "\n",
        "        print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "            num_correct / num_total * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQL1lJdaRPT1"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AGHbyABRPz3",
        "outputId": "f7e77a9a-e5f4-4125-9494-cb08e6752abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Teacher-------\n",
            "Epoch 1: Class_accuracy: 98.17%\n",
            "Epoch 2: Class_accuracy: 98.65%\n",
            "Epoch 3: Class_accuracy: 98.81%\n",
            "Epoch 4: Class_accuracy: 98.87%\n",
            "Epoch 5: Class_accuracy: 98.99%\n",
            "Epoch 6: Class_accuracy: 99.11%\n",
            "Epoch 7: Class_accuracy: 99.05%\n",
            "Epoch 8: Class_accuracy: 99.30%\n",
            "Epoch 9: Class_accuracy: 99.20%\n",
            "Epoch 10: Class_accuracy: 99.28%\n",
            "Epoch 11: Class_accuracy: 99.31%\n",
            "Epoch 12: Class_accuracy: 99.32%\n",
            "------Student-------\n",
            "Epoch 1: Class_accuracy: 96.72%\n",
            "Epoch 2: Class_accuracy: 97.97%\n",
            "Epoch 3: Class_accuracy: 98.22%\n",
            "Epoch 4: Class_accuracy: 98.47%\n",
            "Epoch 5: Class_accuracy: 98.56%\n",
            "Epoch 6: Class_accuracy: 98.60%\n",
            "Epoch 7: Class_accuracy: 98.64%\n",
            "Epoch 8: Class_accuracy: 98.69%\n",
            "Epoch 9: Class_accuracy: 98.77%\n",
            "Epoch 10: Class_accuracy: 98.77%\n",
            "Epoch 11: Class_accuracy: 98.85%\n",
            "Epoch 12: Class_accuracy: 98.83%\n"
          ]
        }
      ],
      "source": [
        "# your code start from here for step 5 \n",
        "print(\"------Teacher-------\")\n",
        "train_and_evaluate(cnn_model, compute_teacher_loss, compute_num_correct)\n",
        "print(\"------Student-------\")\n",
        "train_and_evaluate(fc_model, compute_student_loss, compute_num_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1N38fnRTNB"
      },
      "source": [
        "# Test accuracy vs. tempreture curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX4dbazrRWIz"
      },
      "outputs": [],
      "source": [
        "# your code start from here for step 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNrH_1emRbGA"
      },
      "source": [
        "# Train student from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjospsxIRbQ6"
      },
      "outputs": [],
      "source": [
        "# Build fully connected student.\n",
        "fc_model_no_distillation = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 7\n",
        "\n",
        "\n",
        "\n",
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over subclasses, but does not perform subclass distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_subclass_logits = fc_model_no_distillation(images, training=True)\n",
        "  cross_entropy_loss = \n",
        "  \n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n",
        "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq3JTpQ4RuhR"
      },
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V8GB2yRRuxF"
      },
      "outputs": [],
      "source": [
        "# your code start from here for step 8\n",
        "from keras_flops import get_flops\n",
        "# use get_flops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjwJ5oziRvRn"
      },
      "source": [
        "# Implementing the state-of-the-art KD algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q10lybAFRvZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42420733-c821-4a99-ed8d-eae6fc9f02ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tf.Tensor(-0.842453, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18194246, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8785715, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.94567585, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9595585, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.970881, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.98252964, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9900694, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9942641, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9950528, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.99666977, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9975138, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9977522, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.99732876, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9973302, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.99608374, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.99533606, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.99423504, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9924402, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9901624, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9854827, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9819546, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.97797966, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9737487, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.96846724, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.959044, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9481487, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.93642044, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9303031, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9207053, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.91327524, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8892746, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.93153954, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9279671, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9278536, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.94253063, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.94020605, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9213691, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.91765594, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.88816166, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8990207, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8992896, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8873787, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8813915, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8633585, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8945036, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.85790634, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8545861, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.91432476, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9095559, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8562412, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8682227, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8795495, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8758888, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.89073706, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87703323, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8702173, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.85671043, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8725705, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8526697, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87840796, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8349533, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8546076, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.86804485, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.86897135, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87955236, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8703728, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8813791, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8423753, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8296604, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8261409, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8314824, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.85698795, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87219906, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87517357, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.87266827, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8586631, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.86947155, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.7972541, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8656559, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.81820345, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8671713, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8638921, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.88681936, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.86647654, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8506031, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.84916687, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8359623, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8445053, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8467574, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8368583, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8037214, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8554468, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8461399, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.85657454, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.849463, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.84162617, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8548441, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8275037, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8435869, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.81902504, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8407078, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8495879, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8539758, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8448572, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.81628704, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8520665, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.806623, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.86368847, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.85458755, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8533335, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8205795, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8235011, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.83404636, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.8435998, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-488aa8bf7cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mupdated_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_SubClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_num_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0dfa8e6fc0fa>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, compute_loss_fn, compute_num_correct)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m#print(\"loss value \" + str(loss_value.numpy()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;31m# more sense.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       output_shape_kept_dims = math_ops.reduced_shape(input_shape,\n\u001b[0;32m--> 212\u001b[0;31m                                                       op.inputs[1])\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape_kept_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduced_shape\u001b[0;34m(input_shape, axes)\u001b[0m\n\u001b[1;32m   4493\u001b[0m   \u001b[0;31m# is fully defined here, which may be faster executing eagerly than running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4494\u001b[0m   \u001b[0;31m# `tf.shape` and then fetching its constant value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4495\u001b[0;31m   \u001b[0mconstant_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4496\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconstant_input_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4497\u001b[0m     \u001b[0mconstant_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnimplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       \u001b[0;31m# Some EagerTensors may not implement .numpy/resolve, e.g. parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# your code start from here for step 12\n",
        "class CNN_SubClass:\n",
        "  def __init__(self, num_of_subclass, temperature, beta):\n",
        "    self.num_of_subclass = num_of_subclass\n",
        "    self.temperature = temperature\n",
        "    self.beta = beta\n",
        "    self.model = tf.keras.Sequential()\n",
        "\n",
        "    # your code start from here for stpe 2\n",
        "    self.model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    self.model.add(layers.MaxPooling2D((2, 2), strides=(1, 1)))\n",
        "    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    self.model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    self.model.add(layers.Flatten())\n",
        "    self.model.add(layers.Dropout(0.5))\n",
        "    self.model.add(layers.Dense(128, activation='relu'))\n",
        "    self.model.add(layers.Dropout(0.5))\n",
        "    self.model.add(layers.Dense(10*num_of_subclass))\n",
        "  \n",
        "  def loss_function(self, images, labels):\n",
        "\n",
        "    subclass_logits = self.model(images, training=True)\n",
        "    # tf.shape(subclass_logits)[0] is batch size \n",
        "    # sum all subclass of a class, get back size 256 x 10 logits \n",
        "    class_logits = tf.reduce_sum(tf.reshape(subclass_logits, (tf.shape(subclass_logits)[0], 10, self.num_of_subclass)),axis=2)\n",
        "    cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=class_logits))\n",
        "\n",
        "    mean = tf.math.reduce_mean(subclass_logits, axis=1)\n",
        "    var = tf.math.reduce_variance(subclass_logits, axis=1)\n",
        "    \n",
        "    normalize = tf.keras.layers.Normalization(axis=0, mean=mean, variance=var)\n",
        "    #normalized_logits = normalize(subclass_logits)\n",
        "    normalized_logits = subclass_logits\n",
        "\n",
        "  \n",
        "    # dot product to get to 256 by 256 size \n",
        "    # input 256 * 30, so M dot M.T\n",
        "    \n",
        "    # summing all rows to get exponential sum \n",
        "    exp_sum = tf.reduce_sum(\n",
        "        #dot product of normalized logit with it self\n",
        "        tf.math.exp(tf.tensordot(\n",
        "            normalized_logits, \n",
        "            tf.transpose(normalized_logits), 1) / self.temperature),\n",
        "            axis=1)\n",
        "  \n",
        "    \n",
        "    log_avg = tf.reduce_mean(tf.math.log(exp_sum))\n",
        "    # n = batch size \n",
        "    aux_loss = log_avg - 1 / self.temperature - np.log(tf.shape(subclass_logits)[0])\n",
        "    print(aux_loss)\n",
        "\n",
        "    total_loss = cross_entropy_loss_value  + self.beta * aux_loss\n",
        "\n",
        "    #print(total_loss)\n",
        "\n",
        "    return total_loss \n",
        "  \n",
        "  def compute_num_correct(self, model, images, labels):\n",
        "    subclass_logits = model(images, training=False)\n",
        "    # tf.shape(subclass_logits)[0] is batch size \n",
        "    class_logits = tf.reduce_sum(tf.reshape(subclass_logits, (tf.shape(subclass_logits)[0], 10, self.num_of_subclass)),axis=2)\n",
        "    \n",
        "    return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "updated_cnn = CNN_SubClass(2, 1, 1)\n",
        "\n",
        "train_and_evaluate(updated_cnn.model, updated_cnn.loss_function, updated_cnn.compute_num_correct)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dsOmtqdieIC"
      },
      "source": [
        "# (Optional) XAI method to explain models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0IMIFW8ilPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba437ce4-a048-4837-eb7c-451082b4d16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(20.847279, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# your code start from here for step 13\n",
        "\n",
        "#Test loss function \n",
        "\n",
        "x = tf.random.uniform(shape=[500, 40], dtype=tf.float32)\n",
        "y = tf.reduce_sum(\n",
        "    tf.reshape(x, (500, 20, 2)),\n",
        "    axis=2\n",
        ")\n",
        "#print(y)\n",
        "mean = tf.math.reduce_mean(y, axis=1)\n",
        "#print(mean)\n",
        "var = tf.math.reduce_variance(y, axis=1)\n",
        "#print(var)\n",
        "layer = tf.keras.layers.Normalization(axis= 0, mean=mean, variance=var)\n",
        "z = layer(y)\n",
        "\n",
        "#print(tf.math.exp(tf.tensordot(z, tf.transpose(z), 1)))\n",
        "\n",
        "#print(z[:,0])\n",
        "#print(tf.math.exp(tf.tensordot(tf.transpose(z[:,0]), z, 1)))\n",
        "#print(tf.tensordot(z, tf.transpose(z), 1))\n",
        "'''\n",
        "print(tf.reduce_sum(tf.math.exp(tf.tensordot(tf.transpose(z[:,0]), z, 1))))\n",
        "'''\n",
        "exp_sum = tf.reduce_sum(\n",
        "    tf.math.exp(tf.tensordot(z, tf.transpose(z), 1)),\n",
        "    axis=1)\n",
        "\n",
        "log_avg = tf.reduce_mean(tf.math.log(exp_sum))\n",
        "# n = batch size \n",
        "aux_loss = log_avg - 1 - np.log(500)\n",
        "print(aux_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = [[  0.21940991, 1.821567], [-0.03301997,  1.5130547]]\n",
        "\n",
        "b = [[  0.21940991, 1.821567], [-0.03301997,  1.5130547]]\n",
        "\n",
        "\n",
        "\n",
        "c = np.dot(a,np.transpose(b))\n",
        "\n",
        "a_t = tf.constant(a)\n",
        "b_t = tf.constant(b)\n",
        "\n",
        "print(c)\n",
        "print(tf.tensordot(a_t, tf.transpose(b_t),1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlLO_VoywdQg",
        "outputId": "9fc0ce4f-fd06-4505-8512-befb479be2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.36624704 2.7488856 ]\n",
            " [2.7488856  2.29042484]]\n",
            "tf.Tensor(\n",
            "[[3.3662474 2.7488859]\n",
            " [2.7488859 2.2904248]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f94825a28f884492ad69986c10ade538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad91a7d35be84776a47ddd331b83918f",
              "IPY_MODEL_087cdf367a0b4fbbb16671b9478c88f7",
              "IPY_MODEL_e57869527ac84b399a15d96695e7ccdd"
            ],
            "layout": "IPY_MODEL_afbd6d79d9734a1bad0501b9048444cc"
          }
        },
        "ad91a7d35be84776a47ddd331b83918f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90094ab48584f048fccabfc0d10edfa",
            "placeholder": "​",
            "style": "IPY_MODEL_a79c15b57ca04df4bead6008e4040f2d",
            "value": "Dl Completed...: 100%"
          }
        },
        "087cdf367a0b4fbbb16671b9478c88f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f972f555fa114f29bac3cae8303e4c18",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3a99df67a754e7fbd74deca132b87ba",
            "value": 4
          }
        },
        "e57869527ac84b399a15d96695e7ccdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a15a8a1d104b438201ea0222e6e131",
            "placeholder": "​",
            "style": "IPY_MODEL_655ed1b7561d46c9bdd72ee66500aa7f",
            "value": " 4/4 [00:00&lt;00:00,  6.38 file/s]"
          }
        },
        "afbd6d79d9734a1bad0501b9048444cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90094ab48584f048fccabfc0d10edfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79c15b57ca04df4bead6008e4040f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f972f555fa114f29bac3cae8303e4c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a99df67a754e7fbd74deca132b87ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79a15a8a1d104b438201ea0222e6e131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655ed1b7561d46c9bdd72ee66500aa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}